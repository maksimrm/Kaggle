{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data-science-bowl-2019/sample_submission.csv\n",
      "/kaggle/input/data-science-bowl-2019/specs.csv\n",
      "/kaggle/input/data-science-bowl-2019/train_labels.csv\n",
      "/kaggle/input/data-science-bowl-2019/test.csv\n",
      "/kaggle/input/data-science-bowl-2019/train.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-db350168c6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Any results you write to the current directory are saved as output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/data-science-bowl-2019/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/data-science-bowl-2019/train_labels.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/data-science-bowl-2019/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m     \"\"\"\n\u001b[1;32m    680\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import json\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "train = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/train.csv\")\n",
    "train_labels = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/train_labels.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/test.csv\")\n",
    "sample_sbmission = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/sample_submission.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stop_events = ['{\"event_code\": 2000, \"event_count\": 1}',\n",
    " '{\"version\":\"1.0\",\"event_count\":1,\"game_time\":0,\"event_code\":2000}',\n",
    " '{\"version\":\"1.0\",\"level\":0,\"round\":0,\"event_count\":1,\"game_time\":0,\"event_code\":2000}',\n",
    " '{\"version\":\"1.0\",\"round\":0,\"event_count\":1,\"game_time\":0,\"event_code\":2000}',\n",
    " '{\"description\":\"Let\\'s set off these fireworks. We can drag them to any height we want!\",\"identifier\":\"Dot_LetsFireworks,Dot_DragAnyHeight\",\"media_type\":\"audio\",\"total_duration\":3885,\"event_count\":2,\"game_time\":0,\"event_code\":3010}',\n",
    " '{\"version\":\"1\",\"round\":0,\"event_count\":1,\"game_time\":0,\"event_code\":2000}',\n",
    "              '{\"event_count\":2,\"game_time\":77,\"event_code\":2025}']\n",
    "\n",
    "\n",
    "def get_data_from(data):\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    features[\"total_time\"] = 0\n",
    "    features[\"time0\"] = 0\n",
    "    features[\"time25\"] = 0\n",
    "    features[\"time50\"] = 0\n",
    "    features[\"time75\"] = 0\n",
    "    features[\"time100\"] = 0\n",
    "    features[\"start_time\"] = 0\n",
    "    features[\"end_time\"] = 0\n",
    "    features[\"day_of_start\"] = 0\n",
    "    features[\"hour_of_start\"] = 0\n",
    "    features[\"day_of_end\"] = 0\n",
    "    features[\"hour_of_end\"] = 0\n",
    "    features[\"num_false\"] = 0\n",
    "    features[\"num_cor\"] = 0\n",
    "    features[\"num_events\"] = len(data)\n",
    "    features[\"type\"] = data[\"type\"].mode().values[0]\n",
    "    features[\"title\"] = data[\"title\"].mode().values[0]\n",
    "    features[\"world\"] = data[\"world\"].mode().values[0]\n",
    "    times = []\n",
    "    descr = []\n",
    "    dict2id = {}\n",
    "    for item in data.values:\n",
    "        d = dict(json.loads(item[3]))\n",
    "        \n",
    "        if \"description\" in d.keys():\n",
    "            descr.append(d[\"description\"])\n",
    "            dict2id[d[\"description\"]] = item[0]\n",
    "        if \"correct\" in d.keys():\n",
    "            if d[\"correct\"]:\n",
    "                features[\"num_cor\"] += 1\n",
    "            else:\n",
    "                features[\"num_false\"] += 1\n",
    "        times.append(d[\"game_time\"])\n",
    "    times = np.array(times)\n",
    "    cnt = Counter(descr).most_common()\n",
    "    features[\"cnt_descr\"] = len(cnt)\n",
    "    if len(cnt) > 0:\n",
    "        features[\"most_popular_dscr\"] = cnt[0][0]\n",
    "        features[\"most_popular_dscr_id\"] = dict2id[cnt[0][0]]\n",
    "        features[\"most_popular_dscr_num\"] = cnt[0][1]\n",
    "        \n",
    "    else: \n",
    "        features[\"most_popular_dscr\"] = None\n",
    "        features[\"most_popular_dscr_id\"] = None\n",
    "        features[\"most_popular_dscr_num\"] = None\n",
    "        \n",
    "        \n",
    "    if len(cnt) > 1:\n",
    "        features[\"most_popular_dscr2\"] = cnt[1][0]\n",
    "        features[\"most_popular_dscr2_id\"] = dict2id[cnt[1][0]]\n",
    "        features[\"most_popular_dscr2_num\"] = cnt[1][1] \n",
    "    else:\n",
    "        features[\"most_popular_dscr2\"] = None\n",
    "        features[\"most_popular_dscr2_id\"] = None\n",
    "        features[\"most_popular_dscr2_num\"] = None\n",
    "    if len(cnt) > 2:\n",
    "        features[\"most_popular_dscr3\"] = cnt[2][0]\n",
    "        features[\"most_popular_dscr3_id\"] = dict2id[cnt[2][0]]\n",
    "        features[\"most_popular_dscr3_num\"] = cnt[2][1]\n",
    "    else:\n",
    "        features[\"most_popular_dscr3\"] = None\n",
    "        features[\"most_popular_dscr3_id\"] = None\n",
    "        features[\"most_popular_dscr3_num\"] = None\n",
    "    features[\"total_time\"] = times.sum()\n",
    "    features[\"time0\"], features[\"time25\"], features[\"time50\"], features[\"time75\"], features[\"time100\"] = np.percentile(times, np.linspace(0, 1, 5))\n",
    "    features[\"start_time\"] = data[\"timestamp\"].min()\n",
    "    features[\"end_time\"] = data[\"timestamp\"].max()\n",
    "    features[\"day_of_start\"] = features[\"start_time\"].day_name()\n",
    "    features[\"hour_of_start\"] = features[\"start_time\"].hour\n",
    "    features[\"day_of_end\"] = features[\"end_time\"].day_name()\n",
    "    features[\"hour_of_end\"] = features[\"end_time\"].hour\n",
    "    features[\"duration\"] = (features[\"end_time\"].value - features[\"start_time\"].value)\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def data_preprocessing(data):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data = data[data[\"event_data\"].apply(lambda x: x not in stop_events)].reset_index(drop = True)\n",
    "    data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
    "    grouped = data.groupby(by = [\"installation_id\", \"game_session\"])\n",
    "    d = grouped.groups\n",
    "    groups = list(d.keys())\n",
    "#     features_data = pd.DataFrame()\n",
    "    dict_for_data = {}\n",
    "    \n",
    "    for i,gr in enumerate(tqdm(groups)):\n",
    "        \n",
    "        features = get_data_from(data.iloc[d[gr]])\n",
    "        \n",
    "        if \"installation_id\" not in dict_for_data.keys():\n",
    "            dict_for_data[\"installation_id\"] = []\n",
    "            dict_for_data[\"game_session\"] = []\n",
    "        dict_for_data[\"installation_id\"].append(gr[0])\n",
    "        dict_for_data[\"game_session\"].append(gr[1])\n",
    "#         features_data.loc[i, \"installation_id\"] = gr[0]\n",
    "#         features_data.loc[i, \"game_session\"] = gr[1]\n",
    "        for key in list(features.keys()):\n",
    "            if key not in dict_for_data.keys():\n",
    "                dict_for_data[key] = []\n",
    "            dict_for_data[key].append(features[key])\n",
    "#             features_data.loc[i, key] = features[key]\n",
    "    features_data = pd.DataFrame(dict_for_data)\n",
    "    \n",
    "    \n",
    "    features_data = features_data.sort_values(by = [\"start_time\", \"end_time\"]).reset_index(drop = True)\n",
    "    return features_data\n",
    "\n",
    "\n",
    "def merge_train(prep_data, train_labels):\n",
    "    return train_labels.merge(prep_data, how = \"left\", on = [\"game_session\", \"installation_id\"]).sort_values(by = [\"start_time\", \"end_time\"]).reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "prep_data = data_preprocessing(train)\n",
    "# prep_data.to_csv(\"prep_data.csv\")\n",
    "\n",
    "prep_test = data_preprocessing(test)\n",
    "# prep_test.to_csv(\"prep_test.csv\")\n",
    "\n",
    "\n",
    "for_train = merge_train(prep_data, train_labels)\n",
    "\n",
    "cat_columns = ['title_y', 'world', 'most_popular_dscr', 'most_popular_dscr_id', 'most_popular_dscr2', 'most_popular_dscr2_id', \n",
    "              'most_popular_dscr3', 'most_popular_dscr3_id', 'day_of_start', 'day_of_end']\n",
    "\n",
    "numeric_columns = ['total_time', 'time0',\n",
    "       'time25', 'time50', 'time75', 'time100', 'start_time', 'end_time',\n",
    "        'hour_of_start', 'hour_of_end',\n",
    "       'num_false', 'num_cor', 'num_events','most_popular_dscr_num',\n",
    "               'most_popular_dscr2_num',  'most_popular_dscr3_num', 'duration'    \n",
    "                  ]\n",
    "\n",
    "target1 = 'num_correct'\n",
    "target2 = 'num_incorrect'\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "\n",
    "for_train[cat_columns] = for_train[cat_columns].fillna(\"Na\")\n",
    "for_train[numeric_columns] = for_train[numeric_columns].fillna(0)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(for_train,for_train[target1], test_size = 0.3, shuffle = False)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(for_train,for_train[target2], test_size = 0.3, shuffle = False)\n",
    "\n",
    "params1= {'bagging_temperature': 0.05363349091949243,\n",
    "   'depth': 4,\n",
    "   'iterations': 960,\n",
    "   'l2_leaf_reg': 1.4404906764735232,\n",
    "   'learning_rate': 0.04306412229499572,\n",
    "   'max_ctr_complexity': 6,\n",
    "   'model_size_reg': 9.33853472553047,\n",
    "   'random_strength': 0.5477062496599889,\n",
    "          \"has_time\" : True}\n",
    "\n",
    "model = CatBoostClassifier(**params1)\n",
    "\n",
    "model.fit(X_train1[cat_columns + numeric_columns], y_train1,\n",
    "          eval_set = (X_test1[cat_columns + numeric_columns], y_test1), \n",
    "          cat_features=cat_columns, plot = True)\n",
    "\n",
    "pred1 = model.predict(X_test1[cat_columns + numeric_columns])\n",
    "\n",
    "params2 ={'bagging_temperature': 8.322400566687106,\n",
    "'depth': 4,\n",
    "'iterations': 5000,\n",
    "'l2_leaf_reg': 30.306334651665228,\n",
    "'learning_rate': 0.002511844524894725,\n",
    "'max_ctr_complexity': 7,\n",
    "'model_size_reg': 5.6099373073302345,\n",
    "'random_strength': 2.320658986302457,\n",
    "      \"has_time\" : True}\n",
    "\n",
    "model2 = CatBoostRegressor(**params2)\n",
    "model2.fit(X_train2[cat_columns + numeric_columns], y_train2,\n",
    "          eval_set = (X_test2[cat_columns + numeric_columns], y_test2), \n",
    "          cat_features=cat_columns, plot = True)\n",
    "\n",
    "pred2 = model2.predict(X_test2[cat_columns + numeric_columns])\n",
    "\n",
    "plt.plot(y_test2, pred2, \".\")\n",
    "plt.plot(y_test2, y_test2)\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def qwk(a1, a2):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n",
    "\n",
    "    :param a1:\n",
    "    :param a2:\n",
    "    :param max_rat:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "\n",
    "    e = e / a1.shape[0]\n",
    "\n",
    "    return 1 - o / e\n",
    "\n",
    "\n",
    "def eval_qwk_lgb(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "\n",
    "#     y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n",
    "    return 'cappa', qwk(y_true, y_pred), True\n",
    "\n",
    "def make_pred(pred1, pred2, a, b):\n",
    "    y_pred1 = np.zeros(len(pred1)) \n",
    "    y_pred1[(pred1!= 0) & (pred2 >= a)] = 1\n",
    "    y_pred1[(pred1!= 0) & (pred2 >= b) & (pred2 < a)] = 2\n",
    "    y_pred1[(pred1!= 0) &  (pred2 < b)] = 3\n",
    "    return y_pred1\n",
    "\n",
    "y_pred1 = make_pred(pred1, pred2, 1.5, 0.6)\n",
    "\n",
    "eval_qwk_lgb(X_test1[\"accuracy_group\"].values, make_pred(pred1, pred2, 1.5, 0.6))\n",
    "\n",
    "prep_test['title_y'] = prep_test[\"title\"]\n",
    "\n",
    "prep_test[numeric_columns] = prep_test[numeric_columns].fillna(0)\n",
    "prep_test[cat_columns] = prep_test[cat_columns].fillna(\"Na\")\n",
    "\n",
    "final_pred1 = model.predict(prep_test[prep_test[\"type\"] == \"Assessment\"][cat_columns + numeric_columns])\n",
    "final_pred2 = model2.predict(prep_test[prep_test[\"type\"] == \"Assessment\"][cat_columns + numeric_columns])\n",
    "final_pred = make_pred(final_pred1, final_pred2, 1.5, 0.6)\n",
    "ids = prep_test[prep_test[\"type\"] == \"Assessment\"][\"installation_id\"]\n",
    "for i, inst in enumerate(sample_submission[\"installation_id\"].values):\n",
    "    sample_submission.loc[i, \"accuracy_group\"] = final_pred[ids == inst].mean()\n",
    "    \n",
    "sample_submission = sample_submission.fillna(0)\n",
    "sample_submission[\"accuracy_group\"] = sample_submission[\"accuracy_group\"].astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
